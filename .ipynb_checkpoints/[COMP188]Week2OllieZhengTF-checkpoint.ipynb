{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 COMP188\n",
    "## Dissecting Filipino family income and expenditure dataset\n",
    "\n",
    "This week we are dissecting the [Filipino family income and expenditure dataset from Kaggle](https://www.kaggle.com/grosvenpaul/family-income-and-expenditure), with the methods used by [Google's tutorial on TensorFlow](https://developers.google.com/machine-learning/crash-course/first-steps-with-tensorflow/video-lecture). \n",
    "\n",
    "We'll be using TensorFlow's Linear Regressor to predict total family expediture from features of the family head as well as other family metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ollie\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "from sklearn import metrics \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import cm\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "tf.__version__ \n",
    "#I ran into problems with tensorflow being on an ancient version on my desktop's Anaconda, seems to work fine on my laptop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll load and examine our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Family Income and Expenditure.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Household Income</th>\n",
       "      <th>Region</th>\n",
       "      <th>Total Food Expenditure</th>\n",
       "      <th>Main Source of Income</th>\n",
       "      <th>Agricultural Household indicator</th>\n",
       "      <th>Bread and Cereals Expenditure</th>\n",
       "      <th>Total Rice Expenditure</th>\n",
       "      <th>Meat Expenditure</th>\n",
       "      <th>Total Fish and  marine products Expenditure</th>\n",
       "      <th>Fruit Expenditure</th>\n",
       "      <th>...</th>\n",
       "      <th>Number of Refrigerator/Freezer</th>\n",
       "      <th>Number of Washing Machine</th>\n",
       "      <th>Number of Airconditioner</th>\n",
       "      <th>Number of Car, Jeep, Van</th>\n",
       "      <th>Number of Landline/wireless telephones</th>\n",
       "      <th>Number of Cellular phone</th>\n",
       "      <th>Number of Personal Computer</th>\n",
       "      <th>Number of Stove with Oven/Gas Range</th>\n",
       "      <th>Number of Motorized Banca</th>\n",
       "      <th>Number of Motorcycle/Tricycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>480332</td>\n",
       "      <td>CAR</td>\n",
       "      <td>117848</td>\n",
       "      <td>Wage/Salaries</td>\n",
       "      <td>0</td>\n",
       "      <td>42140</td>\n",
       "      <td>38300</td>\n",
       "      <td>24676</td>\n",
       "      <td>16806</td>\n",
       "      <td>3325</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198235</td>\n",
       "      <td>CAR</td>\n",
       "      <td>67766</td>\n",
       "      <td>Wage/Salaries</td>\n",
       "      <td>0</td>\n",
       "      <td>17329</td>\n",
       "      <td>13008</td>\n",
       "      <td>17434</td>\n",
       "      <td>11073</td>\n",
       "      <td>2035</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82785</td>\n",
       "      <td>CAR</td>\n",
       "      <td>61609</td>\n",
       "      <td>Wage/Salaries</td>\n",
       "      <td>1</td>\n",
       "      <td>34182</td>\n",
       "      <td>32001</td>\n",
       "      <td>7783</td>\n",
       "      <td>2590</td>\n",
       "      <td>1730</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107589</td>\n",
       "      <td>CAR</td>\n",
       "      <td>78189</td>\n",
       "      <td>Wage/Salaries</td>\n",
       "      <td>0</td>\n",
       "      <td>34030</td>\n",
       "      <td>28659</td>\n",
       "      <td>10914</td>\n",
       "      <td>10812</td>\n",
       "      <td>690</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189322</td>\n",
       "      <td>CAR</td>\n",
       "      <td>94625</td>\n",
       "      <td>Wage/Salaries</td>\n",
       "      <td>0</td>\n",
       "      <td>34820</td>\n",
       "      <td>30167</td>\n",
       "      <td>18391</td>\n",
       "      <td>11309</td>\n",
       "      <td>1395</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total Household Income Region  Total Food Expenditure  \\\n",
       "0                  480332    CAR                  117848   \n",
       "1                  198235    CAR                   67766   \n",
       "2                   82785    CAR                   61609   \n",
       "3                  107589    CAR                   78189   \n",
       "4                  189322    CAR                   94625   \n",
       "\n",
       "  Main Source of Income  Agricultural Household indicator  \\\n",
       "0         Wage/Salaries                                 0   \n",
       "1         Wage/Salaries                                 0   \n",
       "2         Wage/Salaries                                 1   \n",
       "3         Wage/Salaries                                 0   \n",
       "4         Wage/Salaries                                 0   \n",
       "\n",
       "   Bread and Cereals Expenditure  Total Rice Expenditure  Meat Expenditure  \\\n",
       "0                          42140                   38300             24676   \n",
       "1                          17329                   13008             17434   \n",
       "2                          34182                   32001              7783   \n",
       "3                          34030                   28659             10914   \n",
       "4                          34820                   30167             18391   \n",
       "\n",
       "   Total Fish and  marine products Expenditure  Fruit Expenditure  \\\n",
       "0                                        16806               3325   \n",
       "1                                        11073               2035   \n",
       "2                                         2590               1730   \n",
       "3                                        10812                690   \n",
       "4                                        11309               1395   \n",
       "\n",
       "               ...                Number of Refrigerator/Freezer  \\\n",
       "0              ...                                             1   \n",
       "1              ...                                             0   \n",
       "2              ...                                             0   \n",
       "3              ...                                             0   \n",
       "4              ...                                             1   \n",
       "\n",
       "   Number of Washing Machine  Number of Airconditioner  \\\n",
       "0                          1                         0   \n",
       "1                          1                         0   \n",
       "2                          0                         0   \n",
       "3                          0                         0   \n",
       "4                          0                         0   \n",
       "\n",
       "   Number of Car, Jeep, Van  Number of Landline/wireless telephones  \\\n",
       "0                         0                                       0   \n",
       "1                         0                                       0   \n",
       "2                         0                                       0   \n",
       "3                         0                                       0   \n",
       "4                         0                                       0   \n",
       "\n",
       "   Number of Cellular phone  Number of Personal Computer  \\\n",
       "0                         2                            1   \n",
       "1                         3                            1   \n",
       "2                         0                            0   \n",
       "3                         1                            0   \n",
       "4                         3                            0   \n",
       "\n",
       "   Number of Stove with Oven/Gas Range  Number of Motorized Banca  \\\n",
       "0                                    0                          0   \n",
       "1                                    0                          0   \n",
       "2                                    0                          0   \n",
       "3                                    0                          0   \n",
       "4                                    0                          0   \n",
       "\n",
       "   Number of Motorcycle/Tricycle  \n",
       "0                              1  \n",
       "1                              2  \n",
       "2                              0  \n",
       "3                              0  \n",
       "4                              1  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also want to get used to using pandas so I'll do some basic dataframe tasks. We'll get rid of some unnecessary data in order to run it faster and make it cleaner to look at.\n",
    "\n",
    "We'll then sum up all the expenses, then remove all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "if \"Total Food Expenditure\" in list(df):    \n",
    "    df = df.drop(\"Total Food Expenditure\", 1)\n",
    "\n",
    "reg = re.compile('.*(([Ee]xpenditure)|([Ee]xpenses))$')\n",
    "expenditure_types = [var for var in list(df) if re.match(reg, var)]\n",
    "df[\"TotalExpenditure\"] = np.sum(df[expenditure_types],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also get rid of `Total Household Income` and `Number of *` because that's cheating as it would very likely highly correlate with total expenditure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg_number = re.compile('Number.*')\n",
    "reg_house = re.compile('House .*')\n",
    "reg_type = re.compile('Type .*')\n",
    "\n",
    "remove = [var for var in list(df) if re.match(reg_number, var) \n",
    "                                  or re.match(reg_house, var) \n",
    "                                  or re.match(reg_type, var)]  + expenditure_types\n",
    "\n",
    "for var in remove:\n",
    "    if var in list(df):\n",
    "        df = df.drop(var, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the Model!\n",
    "So now we wanna predict `Total Expenditures` through household parameters. Lets first shuffle the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.reindex(np.random.permutation(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining our feature\n",
    "For just using a single predictor, we could use variables like `Imputed House Rental Value` or `Total Income from Entrepreneurial Activites` but it's effect would be a little too obvious and statistically significant. \n",
    "\n",
    "It would seem interesting to use `Household Head Age` as a predictor, so we'll use it as a numerical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I discovered that TensorFlow doesn't take white space when considering variable names\n",
    "#this is meant to nuke all whitespaces \n",
    "df = df.rename(index=str, columns={var:(re.sub('[\\s+]', '', var))for var in list(df)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df[[\"HouseholdHeadAge\"]]\n",
    "X_attr = [tf.feature_column.numeric_column(\"HouseholdHeadAge\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining our target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df[[\"TotalExpenditure\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting our Linear Regression Engine\n",
    "We'll use the `GradientDescentOptimizer` to train our model.\n",
    "\n",
    "The TensorFlow tutorial also uses gradient clipping to limit the magnitude of gradients, which would drastically over-shoot the gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\TENSORFLOWTEMP', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000000DDE33C7588>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "optim = tf.train.GradientDescentOptimizer(learning_rate=0.0000001)\n",
    "optim = tf.contrib.estimator.clip_gradients_by_norm(optim, 5.0)\n",
    "\n",
    "lin_regress = tf.estimator.LinearRegressor(\n",
    "    feature_columns = X_attr,\n",
    "    optimizer = optim,\n",
    "    model_dir = \"C:\\\\TENSORFLOWTEMP\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Defining our input function\n",
    "Our input function will process our pandas data into numpy arrays where TensorFlow can easily process them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inputer(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
    "    features = {key:np.array(value) for key,value in dict(features).items()}\n",
    "    \n",
    "    ds = Dataset.from_tensor_slices((features, targets))\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=10000)\n",
    "    \n",
    "    features, labels = ds.make_one_shot_iterator().get_next()\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\TENSORFLOWTEMP\\model.ckpt-400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 401 into C:\\TENSORFLOWTEMP\\model.ckpt.\n",
      "INFO:tensorflow:loss = 15479835000.0, step = 401\n",
      "INFO:tensorflow:Saving checkpoints for 500 into C:\\TENSORFLOWTEMP\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 140120700000.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0xdde1d51630>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gotta restart the kernel or name the training or else it'll give us an IndexError\n",
    "lin_regress.train(\n",
    "    input_fn = lambda:inputer(X, y),\n",
    "    steps = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets evaluate it.\n",
    "We'll use MSE and RMSE to evaluate the effectiveness of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\TENSORFLOWTEMP\\model.ckpt-500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "MSE: 62977766549.368\tRMSE: 250953.714\tR^2: -1.574\n"
     ]
    }
   ],
   "source": [
    "y_pred = lin_regress.predict(input_fn=lambda: inputer(X, y, num_epochs=1, shuffle=False))\n",
    "\n",
    "y_pred = np.array([pred_row[\"predictions\"][0] for pred_row in y_pred])\n",
    "mse = metrics.mean_squared_error(y_pred, y)\n",
    "\n",
    "r2 = metrics.r2_score(y, y_pred)\n",
    "\n",
    "sum_stats = {\n",
    "    \"mse\" : mse,\n",
    "    \"rmse\" : math.sqrt(mse),\n",
    "    \"r2\" : r2\n",
    "            }\n",
    "print(\"MSE: %0.3f\\tRMSE: %0.3f\\tR^2: %0.3f\" % (sum_stats[\"mse\"], sum_stats[\"rmse\"], sum_stats[\"r2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end using household head age, has very little predictive power in determining `Total Expenditure` with an almost negligable R^2 and highly variable root mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIN: 11055.000\tMAX: 4650633.000\n"
     ]
    }
   ],
   "source": [
    "sum_stats.update({\n",
    "    \"min\":df[\"TotalExpenditure\"].min(),\n",
    "    \"max\":df[\"TotalExpenditure\"].max()\n",
    "            })\n",
    "\n",
    "print(\"MIN: %0.3f\\tMAX: %0.3f\" %(sum_stats[\"min\"], sum_stats[\"max\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our RMSE doesn't really scale the range of the data, but the max value is not indiciative of the data as...    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAD8CAYAAABQFVIjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xdde6c18b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top10expenditures = df[[\"TotalExpenditure\"]].sort_values(by=\"TotalExpenditure\", ascending = False).values[:10].tolist()\n",
    "top10expenditures = [expenditure[0] for expenditure in top10expenditures]\n",
    "\n",
    "plt.boxplot(top10expenditures)\n",
    "plt.xlabel(\"Expenditures\")\n",
    "plt.ylabel(\"Expenditure Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our 2 most maximum values are outliers as seen by our boxplot with the next maximum value being 3,000,000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range between 3rd highest expenditure and lowest: 2944882.000\tvs.\tRMSE: 250953.714\n"
     ]
    }
   ],
   "source": [
    "print(\"Range between 3rd highest expenditure and lowest: %0.3f\\tvs.\\tRMSE: %0.3f\" % (top10expenditures[2]-sum_stats[\"min\"],\n",
    "                                                                                    sum_stats[\"rmse\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our RMSE still doesn't straddle the range, so our RMSE should be ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calib_data = pd.DataFrame()\n",
    "calib_data[\"predictions\"] = pd.Series(y_pred)\n",
    "calib_data[\"actual\"] = pd.Series(y)\n",
    "calib_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = df.sample(400)\n",
    "\n",
    "x_0 = sample[\"HouseholdHeadAge\"].min()\n",
    "x_1 = sample[\"HouseholdHeadAge\"].max()\n",
    "\n",
    "weight = lin_regress.get_variable_value(\"linear/linear_model/HouseholdHeadAge/weights\")[0]\n",
    "bias = lin_regress.get_variable_value(\"linear/linear_model/bias_weights\")\n",
    "\n",
    "y_0 = weight * x_0 + bias\n",
    "y_1 = weight * x_1 + bias\n",
    "\n",
    "plt.plot([x_0, x_1], [y_0, y_1], c='green')\n",
    "\n",
    "plt.title(\"Househole Head Age vs Total Household Expenditure\")\n",
    "plt.ylabel(\"Total Expenditure\")\n",
    "plt.xlabel(\"Household Head Ages\")\n",
    "\n",
    "plt.scatter(sample[\"HouseholdHeadAge\"], sample[\"TotalExpenditure\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The Linear Regressor is too indecisive to be significant, with clear outliers at all ages.\n",
    "\n",
    "Therefore, Household Age cannot be a good lone predictor of `Total Expenditure`. But we may use it in conjunction with other predictors to make good predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using TensorFlow's supplied function listed below, we'll try to adjust the learning rate such that our RMSE may be better than our previous version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(learning_rate, steps, batch_size, input_feature=\"HouseholdHeadAge\"):\n",
    "  periods = 10\n",
    "  steps_per_period = steps / periods\n",
    "\n",
    "  my_feature = input_feature\n",
    "  my_feature_data = df[[my_feature]]\n",
    "  my_label = \"TotalExpenditure\"\n",
    "  targets = df[my_label]\n",
    "\n",
    "  # Create feature columns\n",
    "  feature_columns = [tf.feature_column.numeric_column(my_feature)]\n",
    "  \n",
    "  # Create input functions\n",
    "  training_input_fn = lambda:inputer(my_feature_data, targets, batch_size=batch_size)\n",
    "  prediction_input_fn = lambda: inputer(my_feature_data, targets, num_epochs=1, shuffle=False)\n",
    "  \n",
    "  # Create a linear regressor object.\n",
    "  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "  linear_regressor = tf.estimator.LinearRegressor(\n",
    "      feature_columns=feature_columns,\n",
    "      optimizer=my_optimizer\n",
    "  )\n",
    "\n",
    "  # Set up to plot the state of our model's line each period.\n",
    "  plt.figure(figsize=(15, 6))\n",
    "  plt.subplot(1, 2, 1)\n",
    "  plt.title(\"Learned Line by Period\")\n",
    "  plt.ylabel(my_label)\n",
    "  plt.xlabel(my_feature)\n",
    "  sample = df.sample(n=300)\n",
    "  plt.scatter(sample[my_feature], sample[my_label])\n",
    "  colors = [cm.coolwarm(x) for x in np.linspace(-1, 1, periods)]\n",
    "\n",
    "  # Train the model, but do so inside a loop so that we can periodically assess\n",
    "  # loss metrics.\n",
    "  print(\"Training model...\")\n",
    "  print(\"RMSE (on training data):\")\n",
    "  root_mean_squared_errors = []\n",
    "  for period in range (0, periods):\n",
    "    # Train the model, starting from the prior state.\n",
    "    linear_regressor.train(\n",
    "        input_fn=training_input_fn,\n",
    "        steps=steps_per_period\n",
    "    )\n",
    "    # Take a break and compute predictions.\n",
    "    predictions = linear_regressor.predict(input_fn=prediction_input_fn)\n",
    "    predictions = np.array([item['predictions'][0] for item in predictions])\n",
    "    \n",
    "    # Compute loss.\n",
    "    root_mean_squared_error = math.sqrt(\n",
    "        metrics.mean_squared_error(predictions, targets))\n",
    "    # Occasionally print the current loss.\n",
    "    print(\"  period %02d : %0.2f\" % (period, root_mean_squared_error))\n",
    "    # Add the loss metrics from this period to our list.\n",
    "    root_mean_squared_errors.append(root_mean_squared_error)\n",
    "    # Finally, track the weights and biases over time.\n",
    "    # Apply some math to ensure that the data and line are plotted neatly.\n",
    "    y_extents = np.array([0, sample[my_label].max()])\n",
    "    \n",
    "    weight = linear_regressor.get_variable_value('linear/linear_model/%s/weights' % input_feature)[0]\n",
    "    bias = linear_regressor.get_variable_value('linear/linear_model/bias_weights')\n",
    "\n",
    "    x_extents = (y_extents - bias) / weight\n",
    "    x_extents = np.maximum(np.minimum(x_extents,\n",
    "                                      sample[my_feature].max()),\n",
    "                           sample[my_feature].min())\n",
    "    y_extents = weight * x_extents + bias\n",
    "    plt.plot(x_extents, y_extents, color=colors[period]) \n",
    "  print(\"Model training finished.\")\n",
    "\n",
    "  # Output a graph of loss metrics over periods.\n",
    "  plt.subplot(1, 2, 2)\n",
    "  plt.ylabel('RMSE')\n",
    "  plt.xlabel('Periods')\n",
    "  plt.title(\"Root Mean Squared Error vs. Periods\")\n",
    "  plt.tight_layout()\n",
    "  plt.plot(root_mean_squared_errors)\n",
    "\n",
    "  # Output a table with calibration data.\n",
    "  calibration_data = pd.DataFrame()\n",
    "  calibration_data[\"predictions\"] = pd.Series(predictions)\n",
    "  calibration_data[\"targets\"] = pd.Series(targets)\n",
    "  display.display(calibration_data.describe())\n",
    "\n",
    "  print(\"Final RMSE (on training data): %0.2f\" % root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Ollie\\AppData\\Local\\Temp\\tmp0rw91wto\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Ollie\\\\AppData\\\\Local\\\\Temp\\\\tmp0rw91wto', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000000DDE3CDCA58>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "Training model...\n",
      "RMSE (on training data):\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Ollie\\AppData\\Local\\Temp\\tmp0rw91wto\\model.ckpt.\n",
      "INFO:tensorflow:loss = 77540530000.0, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 10 into C:\\Users\\Ollie\\AppData\\Local\\Temp\\tmp0rw91wto\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 58864935000.0.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Ollie\\AppData\\Local\\Temp\\tmp0rw91wto\\model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "  period 00 : 250953.68\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Ollie\\AppData\\Local\\Temp\\tmp0rw91wto\\model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 11 into C:\\Users\\Ollie\\AppData\\Local\\Temp\\tmp0rw91wto\\model.ckpt.\n",
      "INFO:tensorflow:loss = 6759132700.0, step = 11\n",
      "INFO:tensorflow:Saving checkpoints for 20 into C:\\Users\\Ollie\\AppData\\Local\\Temp\\tmp0rw91wto\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8469138400.0.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Ollie\\AppData\\Local\\Temp\\tmp0rw91wto\\model.ckpt-20\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-fe3eac9a0307>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.00002\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;32m<ipython-input-61-21e59f1ed4e4>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(learning_rate, steps, batch_size, input_feature)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;31m# Take a break and compute predictions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_regressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprediction_input_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predictions'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# Compute loss.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-61-21e59f1ed4e4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;31m# Take a break and compute predictions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_regressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprediction_input_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predictions'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# Compute loss.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ollie\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, input_fn, predict_keys, hooks, checkpoint_path)\u001b[0m\n\u001b[0;32m    490\u001b[0m           hooks=all_hooks) as mon_sess:\n\u001b[0;32m    491\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m           \u001b[0mpreds_evaluated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpreds_evaluated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ollie\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    544\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 546\u001b[1;33m                           run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ollie\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1020\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m                               run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1023\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[1;32mC:\\Users\\Ollie\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1096\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m       \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ollie\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1168\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1170\u001b[1;33m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ollie\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ollie\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ollie\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ollie\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ollie\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ollie\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    learning_rate=0.00002,\n",
    "    steps=100,\n",
    "    batch_size=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
